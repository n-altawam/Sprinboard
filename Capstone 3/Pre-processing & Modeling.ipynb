{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import os\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directories\n",
    "val_folder = './chest_xray/val/'\n",
    "test_folder = './chest_xray/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-defined load_image function\n",
    "\n",
    "def load_images(folder_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "\n",
    "    for subfolder in os.listdir(folder_path):\n",
    "        subfolder_path = os.path.join(folder_path, subfolder)\n",
    "        if not os.path.isdir(subfolder_path):\n",
    "            continue\n",
    "\n",
    "        label = 'Normal' if subfolder == 'NORMAL' else 'Pneumonia'\n",
    "\n",
    "        for filename in os.listdir(subfolder_path):\n",
    "            file_path = os.path.join(subfolder_path, filename)\n",
    "            img = cv2.imread(file_path)\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "            img = cv2.resize(img, (im_size, im_size))\n",
    "            img = np.expand_dims(img, axis=-1) # adding back color channel\n",
    "            images.append(img)\n",
    "            labels.append(label)\n",
    "\n",
    "    images = np.array(images)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_size = 224\n",
    "val_images, val_labels = load_images(val_folder)\n",
    "test_images, test_labels = load_images(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = np.load('train_images_balanced.npy')\n",
    "train_labels = np.load('train_labels_balanced.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7750, 224, 224, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a binary classification problem we can use Label Indexing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "train_labels_encoded = encoder.fit_transform(train_labels)\n",
    "test_labels_encoded = encoder.fit_transform(test_labels)\n",
    "val_labels_encoded = encoder.fit_transform(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(624,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0 3875]\n",
      " [   1 3875]]\n"
     ]
    }
   ],
   "source": [
    "print(np.asarray(np.unique(train_labels_encoded, return_counts=True)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense,Input,Conv2D,Flatten,MaxPool2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variables\n",
    "input_shape = (im_size,im_size,1)\n",
    "filter1_size = 32\n",
    "filter2_size = 64\n",
    "filter_shape = (3,3)\n",
    "pool_shape = (2,2)\n",
    "\n",
    "# Model architecture implementation\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, filter_shape, activation='relu', input_shape=input_shape))\n",
    "# model.add(Conv2D(64, filter_shape, activation='relu'))\n",
    "model.add(MaxPool2D(pool_shape))\n",
    "\n",
    "# model.add(Conv2D(32, filter_shape, activation='relu'))\n",
    "model.add(Conv2D(64, filter_shape, activation='relu'))\n",
    "model.add(MaxPool2D(pool_shape))\n",
    "\n",
    "\n",
    "#Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEXT TRY OUTPUT to 1 layer using sigmoid activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_input (InputLayer)   [(None, 224, 224, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 111, 111, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 109, 109, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 54, 54, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 186624)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               23888000  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,906,945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable params: 23,906,945\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Dense (output) layer\n",
    "output_shape = model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Create model class\n",
    "model = Model(model.input, model.output)\n",
    "\n",
    "# Print model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#epochs for model training and learning rate for optimizer\n",
    "epochs = 20\n",
    "learning_rate = 1e-2\n",
    "\n",
    "#using Adam optimizer to compile or build the model\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "      loss='categorical_crossentropy',\n",
    "      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "data_generator = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Set the batch size and image size\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "train_dir = './chest_xray/train'\n",
    "# Create the data generators\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    train_dir,\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "243/243 [==============================] - 16s 60ms/step - loss: 0.0000e+00 - accuracy: 0.5008 - val_loss: 0.0000e+00 - val_accuracy: 0.3750\n",
      "Epoch 2/10\n",
      "243/243 [==============================] - 14s 58ms/step - loss: 0.0000e+00 - accuracy: 0.5000 - val_loss: 0.0000e+00 - val_accuracy: 0.3750\n",
      "Epoch 3/10\n",
      "241/243 [============================>.] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.4995"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, train_labels_encoded, epochs=10, batch_size=32, validation_data=(X_test, test_labels_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy Graph\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Accuracy scores')\n",
    "plt.plot(hist.history['accuracy'])\n",
    "plt.plot(hist.history['val_accuracy'])\n",
    "plt.legend(['acc', 'val_acc'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loss Graph\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Loss value')\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"Normal\", \"Pneumonia\"]\n",
    "\n",
    "#confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = model.predict(test_images)\n",
    "\n",
    "#transforming label back to original\n",
    "y_pred = encoder.inverse_transform(y_pred)\n",
    "#matrix of Actual vs Prediction data\n",
    "c_matrix = confusion_matrix(test_labels, y_pred)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.title('Confusion matrix',fontsize=14)\n",
    "sns.heatmap(\n",
    "  c_matrix, xticklabels=labels,yticklabels=labels,\n",
    "  fmt='d', annot=True,annot_kws={\"size\": 14}, cmap='Reds')\n",
    "plt.xlabel(\"Predicted\",fontsize=12)\n",
    "plt.ylabel(\"Actual\",fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(230,280,3):\n",
    "    pred = model.predict(test_images)[i]\n",
    "    #Display the x-ray image\n",
    "    cv2.imshow(\"X-Ray\",test_images[i])\n",
    "    print(\"Actual :\",test_labels[i],\" Predicted :\",labels[np.argmax(pred)])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "accuracy = accuracy_score(test_labels, y_pred)\n",
    "precision = precision_score(test_labels, y_pred)\n",
    "recall = recall_score(test_labels, y_pred)\n",
    "f1_score = f1_score(test_labels, y_pred)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print(\"Precision: \", precision)\n",
    "print(\"Recall: \", recall)\n",
    "print(\"F1 Score: \", f1_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
